{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "\n",
    "from ngram import *\n",
    "from baselines import *\n",
    "from error_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = tidy_labels(pd.concat(load_cf_data()))\n",
    "d = d.dropna(subset=['aggression_score'])\n",
    "d = d.iloc[np.random.permutation(np.arange(d.shape[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "architecture = [50, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram_feature_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range = (1,5), analyzer = 'char', max_features = max_features)),\n",
    "    ('tfidf', TfidfTransformer(sublinear_tf=True,norm='l2')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 75\n",
    "batch_size = 500\n",
    "display_step = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = empirical_dist(d['aggression_score'], w = 0.25)\n",
    "data = get_labeled_comments(d, labels)\n",
    "train, test = train_test_split(data, test_size = 0.2, random_state=0)\n",
    "\n",
    "y_train =train.ix[:, train.columns != 'x'].values\n",
    "y_test =test.ix[:, train.columns != 'x'].values\n",
    "\n",
    "ngram_feature_extractor = ngram_feature_pipeline.fit(train['x'])\n",
    "X_train = ngram_feature_extractor.transform(train['x'])\n",
    "X_test = ngram_feature_extractor.transform(test['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0001 cost= 200.453338623\n",
      "\n",
      "\tTrain RMSE:  11.876830211864322\n",
      "\tTest RMSE:  12.0066542263117\n",
      "\n",
      "\tTrain R^2:  -0.00946412740553\n",
      "\tTest R^2:  -0.00871802623687\n",
      "\n",
      "\n",
      "Batch: 1001 cost= 51.304167497\n",
      "\n",
      "\tTrain RMSE:  0.7548548177104467\n",
      "\tTest RMSE:  0.805283885951192\n",
      "\n",
      "\tTrain R^2:  -0.655800525268\n",
      "\tTest R^2:  -0.518735415726\n",
      "\n",
      "\n",
      "Batch: 2001 cost= 34.789401670\n",
      "\n",
      "\tTrain RMSE:  0.566675978440958\n",
      "\tTest RMSE:  0.6050497697341211\n",
      "\n",
      "\tTrain R^2:  -0.557587572695\n",
      "\tTest R^2:  -0.485284717808\n",
      "\n",
      "\n",
      "Batch: 3001 cost= 19.636608984\n",
      "\n",
      "\tTrain RMSE:  0.45018246841338794\n",
      "\tTest RMSE:  0.4771567124636231\n",
      "\n",
      "\tTrain R^2:  0.241276617386\n",
      "\tTest R^2:  0.184140579519\n",
      "\n",
      "\n",
      "Batch: 4001 cost= 9.769432353\n",
      "\n",
      "\tTrain RMSE:  0.38627761027694735\n",
      "\tTest RMSE:  0.4050118334136526\n",
      "\n",
      "\tTrain R^2:  0.486521315111\n",
      "\tTest R^2:  0.43073138452\n",
      "\n",
      "\n",
      "Batch: 5001 cost= 3.949548425\n",
      "\n",
      "\tTrain RMSE:  0.36048278148966106\n",
      "\tTest RMSE:  0.37884493483603676\n",
      "\n",
      "\tTrain R^2:  0.573137239008\n",
      "\tTest R^2:  0.51761048325\n",
      "\n",
      "\n",
      "Batch: 6001 cost= 1.525451281\n",
      "\n",
      "\tTrain RMSE:  0.34668663367618247\n",
      "\tTest RMSE:  0.3662888075936593\n",
      "\n",
      "\tTrain R^2:  0.625187537554\n",
      "\tTest R^2:  0.571406334073\n",
      "\n",
      "\n",
      "Batch: 7001 cost= 0.593261091\n",
      "\n",
      "\tTrain RMSE:  0.3344068006170109\n",
      "\tTest RMSE:  0.3577605326163301\n",
      "\n",
      "\tTrain R^2:  0.64817337945\n",
      "\tTest R^2:  0.586876349978\n",
      "\n",
      "\n",
      "Batch: 8001 cost= 0.311488945\n",
      "\n",
      "\tTrain RMSE:  0.32547313866126126\n",
      "\tTest RMSE:  0.35292110165270235\n",
      "\n",
      "\tTrain R^2:  0.677642206667\n",
      "\tTest R^2:  0.611176410294\n",
      "\n",
      "\n",
      "Batch: 9001 cost= 0.207619438\n",
      "\n",
      "\tTrain RMSE:  0.31584445752423174\n",
      "\tTest RMSE:  0.3461074249906584\n",
      "\n",
      "\tTrain R^2:  0.695129566384\n",
      "\tTest R^2:  0.625543961641\n",
      "\n",
      "\n",
      "Batch: 10001 cost= 0.174407178\n",
      "\n",
      "\tTrain RMSE:  0.3080491552137129\n",
      "\tTest RMSE:  0.34447580541928224\n",
      "\n",
      "\tTrain R^2:  0.727775339977\n",
      "\tTest R^2:  0.65115094654\n",
      "\n",
      "\n",
      "Batch: 11001 cost= 0.150617607\n",
      "\n",
      "\tTrain RMSE:  0.30269065246368143\n",
      "\tTest RMSE:  0.34283452391627267\n",
      "\n",
      "\tTrain R^2:  0.729964614476\n",
      "\tTest R^2:  0.644979860508\n",
      "\n",
      "\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "classes = np.arange(y_test.shape[1])\n",
    "y_train_mean = y_train.dot(classes).reshape((y_train.shape[0], 1))\n",
    "y_test_mean = y_test.dot(classes).reshape((y_test.shape[0], 1))\n",
    "\n",
    "\n",
    "NN_REG(X_train,\n",
    "        y_train_mean,\n",
    "        X_test,\n",
    "        y_test_mean,\n",
    "        training_epochs = 100,\n",
    "        batch_size = 500,\n",
    "        display_step = 1000,\n",
    "        architecture = architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sk_reg_model = Ridge(alpha = 1.0).fit(X_train, y_train.dot(classes))\n",
    "_ = get_regression_metrics(sk_reg_model.predict(X_test), y_test.dot(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random on Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_b = tidy_labels(load_cf_data()[1])\n",
    "d_b = d_b.dropna(subset=['aggression_score'])\n",
    "\n",
    "labels_b = empirical_dist(d_b['aggression_score'], w = 0.25)\n",
    "data_b = get_labeled_comments(d_b, labels_b)\n",
    "train_b, test_b = train_test_split(data_b, test_size = 0.2, random_state=0)\n",
    "\n",
    "y_train_b =train_b.ix[:, train_b.columns != 'x'].values\n",
    "y_test_b =test_b.ix[:, train_b.columns != 'x'].values\n",
    "\n",
    "ngram_feature_extractor_b = ngram_feature_pipeline.fit(train_b['x'])\n",
    "X_train_b = ngram_feature_extractor_b.transform(train_b['x'])\n",
    "X_test_b = ngram_feature_extractor_b.transform(test_b['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0001 cost= 1618.807006836\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [15993 58672]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6d9401f6e145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdisplay_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         architecture = architecture)\n\u001b[0m",
      "\u001b[0;32m/Users/ellerywulczyn/talk_page_abuse/wikipedia/src/modeling/ngram.py\u001b[0m in \u001b[0;36mNN_REG\u001b[0;34m(X_train, y_train, X_test, y_test, learning_rate, training_epochs, batch_size, display_step, architecture)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\tTrain RMSE: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tTest RMSE: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ellerywulczyn/talk_page_abuse/wikipedia/src/modeling/baselines.py\u001b[0m in \u001b[0;36mrmse\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ellerywulczyn/miniconda3/lib/python3.5/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m    230\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 231\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    232\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[1;32m    233\u001b[0m                                weights=sample_weight)\n",
      "\u001b[0;32m/Users/ellerywulczyn/miniconda3/lib/python3.5/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ellerywulczyn/miniconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[0;32m--> 176\u001b[0;31m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [15993 58672]"
     ]
    }
   ],
   "source": [
    "classes_b = np.arange(y_test.shape[1])\n",
    "y_train_mean_b = y_train_b.dot(classes).reshape((y_train_b.shape[0], 1))\n",
    "y_test_mean_b = y_test_b.dot(classes).reshape((y_test_b.shape[0], 1))\n",
    "\n",
    "\n",
    "NN_REG(X_train,\n",
    "        y_train_mean_b,\n",
    "        X_test_b,\n",
    "        y_test_mean_b,\n",
    "        training_epochs = 100,\n",
    "        batch_size = 500,\n",
    "        display_step = 1000,\n",
    "        architecture = architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk_reg_model_b = Ridge(alpha = 1.0).fit(X_train_b, y_train_b.dot(classes))\n",
    "_ = get_regression_metrics(sk_reg_model.predict(X_test), y_test.dot(classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
