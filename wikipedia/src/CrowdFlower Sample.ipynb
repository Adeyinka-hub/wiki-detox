{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from db_utils import query_hive_ssh\n",
    "import re\n",
    "import copy\n",
    "from diff_utils import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sample\n",
    "Consider comments made since min_timestamp. Take n random comments from non-bot users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Params__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 500000\n",
    "min_timestamp = '2000-01-01T00:00:00Z' # start of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query and Download Time: 13.202378916740418\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    diffs.*\n",
    "FROM\n",
    "    enwiki.user_talk_diff_no_admin diffs\n",
    "WHERE\n",
    "    rev_timestamp > '%(min_timestamp)s'\n",
    "    AND user_text != 'MediaWiki message delivery'\n",
    "    AND user_text != 'Maintenance script'\n",
    "    AND user_text NOT RLIKE 'bot|Bot|BOT'\n",
    "ORDER BY RAND()\n",
    "LIMIT %(n)d\n",
    "\"\"\"\n",
    "\n",
    "params = {\n",
    "    'n': int(n * 1.7),\n",
    "    'min_timestamp': min_timestamp\n",
    "    }\n",
    "\n",
    "df = query_hive_ssh(query % params, '../data/raw_random_sample.tsv', priority = True, quoting=3, delete = False)\n",
    "df.columns = [c.split('.')[1] for c in df.columns]\n",
    "t2 = time.time()\n",
    "print('Query and Download Time:', (t2-t1) / 60.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cleaning and Filtering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: 850000\n",
      "Cleaned:  750065\n",
      "No Few Words:  634086\n",
      "No Few Chars:  616688\n",
      "Cleaning and Filtering Time: 5.818535614013672\n"
     ]
    }
   ],
   "source": [
    "df = clean_and_filter(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dr. Blofeld    1935\n",
       "NawlinWiki     1740\n",
       "Drmies         1185\n",
       "Gogo Dodo      1058\n",
       "JohnCD         1016\n",
       "Name: user_text, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show_comments(df, 10)\n",
    "df['user_text'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show_comments(reduced_df[reduced_df['user_text'] == 'NawlinWiki'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Save File__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[:1000].to_csv('../data/1k_random_sample.tsv', sep = '\\t')\n",
    "df[:n].to_csv('../data/%dk_random_sample.tsv' % (int(n / 1000)), sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Blocked User Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query and Download Time: 131.84529133240383\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    diffs.*\n",
    "FROM\n",
    "    enwiki.blocked_user_talk_diff_no_admin diffs\n",
    "\"\"\"\n",
    "df = query_hive_ssh(query % params, '../data/raw_all_blocked_user.tsv', priority = True, quoting=3, delete = False)\n",
    "df.columns = [c.split('.')[1] for c in df.columns]\n",
    "t2 = time.time()\n",
    "print('Query and Download Time:', (t2-t1) / 60.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cleaning and Filtering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: 1958725\n",
      "Cleaned:  1769861\n",
      "No Few Words:  1508683\n",
      "No Few Chars:  1472414\n",
      "Cleaning and Filtering Time: 9.795163734753926\n"
     ]
    }
   ],
   "source": [
    "df = clean_and_filter(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dr. Blofeld         53072\n",
       "Drmies              33009\n",
       "SandyGeorgia        27167\n",
       "Malleus Fatuorum    20112\n",
       "Alansohn            17782\n",
       "Name: user_text, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_text'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Save File__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[:1000].to_csv('../data/1k_blocked_user.tsv', sep = '\\t')\n",
    "df.to_csv('../data/all_blocked_user.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onionize `all_blocked_user`\n",
    "\n",
    "We want to get the k posts before and after each block event for different values of [k1, k2, ..kn]. In order for us to grow k as we please without labeling headaches, we will create a file containing the k_i-1 through k_i posts for each block event that we have not yet labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12095\n"
     ]
    }
   ],
   "source": [
    "users = list(set(df['user_text']))\n",
    "print(len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "      *\n",
    "FROM\n",
    "    enwiki.block_events\n",
    "\"\"\"\n",
    "\n",
    "block_events_df = query_hive_ssh(query, 'scratch.tsv', priority = True, quoting=3, delete=False)\n",
    "block_events_df.columns = [c.split('.')[1] for c in block_events_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0003859996795654297\n",
      "1000\n",
      "82.6041669845581\n",
      "2000\n",
      "81.06537508964539\n",
      "3000\n",
      "83.32149386405945\n",
      "4000\n",
      "85.06976103782654\n",
      "5000\n",
      "83.52438592910767\n",
      "6000\n",
      "81.97109293937683\n",
      "7000\n",
      "83.9028480052948\n",
      "8000\n",
      "83.64466905593872\n",
      "9000\n",
      "83.38026404380798\n",
      "10000\n",
      "83.4719750881195\n",
      "11000\n",
      "80.05310487747192\n",
      "12000\n",
      "80.89337086677551\n"
     ]
    }
   ],
   "source": [
    "k_prev = 0\n",
    "ks = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 500, 1000]\n",
    "dfs = {k:[] for k in ks}\n",
    "\n",
    "t1 = time.time()\n",
    "for i, user in enumerate(users):\n",
    "    if i % 1000 ==0:\n",
    "        print (i)\n",
    "        print(time.time()-t1)\n",
    "        t1 = time.time()\n",
    "    df_user = df[df['user_text'] == user].sort_values(by='rev_timestamp')\n",
    "    if df_user.shape[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    block_events_df_user = block_events_df[block_events_df['user_text']==user]\n",
    "    seen_ids = set()\n",
    "\n",
    "\n",
    "    for i,r in block_events_df_user.iterrows():\n",
    "        ts = r['timestamp']\n",
    "        for k in ks:\n",
    "            df_user_pre = df_user[df_user['rev_timestamp'] <= ts][-k:]\n",
    "\n",
    "            if df_user_pre.shape[0] > 0:\n",
    "                df_user_pre = df_user_pre[df_user_pre['rev_id'].apply(lambda x: x not in seen_ids )]\n",
    "                if df_user_pre.shape[0] > 0:\n",
    "                    seen_ids.update(tuple(df_user_pre['rev_id']))\n",
    "                    dfs[k].append(df_user_pre)\n",
    "                    \n",
    "            df_user_post = df_user[df_user['rev_timestamp'] > ts][:k]\n",
    "            if df_user_post.shape[0] > 0:\n",
    "                df_user_post = df_user_post[df_user_post['rev_id'].apply(lambda x: x not in seen_ids ) ]\n",
    "                if df_user_post.shape[0] > 0:\n",
    "                    seen_ids.update(tuple(df_user_post['rev_id']))\n",
    "                    dfs[k].append(df_user_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = {k: pd.concat(v) for k,v in dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 50526),\n",
       " (10, 25078),\n",
       " (20, 35494),\n",
       " (30, 27627),\n",
       " (40, 24018),\n",
       " (50, 21517),\n",
       " (60, 19690),\n",
       " (70, 18298),\n",
       " (80, 17079),\n",
       " (90, 16078),\n",
       " (100, 15278),\n",
       " (150, 67256),\n",
       " (200, 57897),\n",
       " (250, 50883),\n",
       " (300, 44782),\n",
       " (500, 144763),\n",
       " (1000, 248064)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = [(k, len(v)) for k,v in dfs.items()]\n",
    "sizes.sort(key=lambda x: x[0])\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in dfs.items():\n",
    "    v.to_csv('../data/blocked_user_onion/%d.tsv' % k, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
