{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from db_utils import query_hive_ssh\n",
    "import re\n",
    "import copy\n",
    "from diff_utils import *\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [  \n",
    "    {\n",
    "        'table':'blocked_talk_diff_no_admin',\n",
    "        'partition':'ns=article', \n",
    "        'ns': 'article',\n",
    "        'name': 'all_blocked_user',\n",
    "    },\n",
    "    {\n",
    "        'table':'blocked_talk_diff_no_admin',\n",
    "        'partition':'ns=user', \n",
    "        'ns': 'user',\n",
    "        'name': 'all_blocked_user',\n",
    "    },\n",
    "    {\n",
    "        'table':'user_talk_diff_no_admin_sample',\n",
    "        'partition':'', \n",
    "        'ns': 'user',\n",
    "        'name': 'talk_diff_no_admin_sample',\n",
    "    },\n",
    "    {\n",
    "        'table':'article_talk_diff_no_admin_sample',\n",
    "        'partition':'', \n",
    "        'ns': 'article',\n",
    "        'name': 'talk_diff_no_admin_sample',\n",
    "    },\n",
    "    {\n",
    "        'table':'talk_diff_no_admin',\n",
    "        'partition':'ns=article/year=2015', \n",
    "        'ns': 'article',\n",
    "        'name': 'talk_diff_no_admin_2015',\n",
    "    },\n",
    "    {\n",
    "        'table':'talk_diff_no_admin',\n",
    "        'partition':'ns=user/year=2015', \n",
    "        'ns': 'user',\n",
    "        'name': 'talk_diff_no_admin_2015',\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transfer_partition(params, dry = False):\n",
    "    hdfs_path = '/user/hive/warehouse/enwiki.db/%(table)s/%(partition)s' % params\n",
    "    stat2_path = '/home/ellery/talk_page_abuse/wikipedia/data/samples/%(ns)s/%(name)s' % params\n",
    "    local_path = '/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/samples/%(ns)s/%(name)s/' % params\n",
    "\n",
    "    if not dry:\n",
    "        # transfer from HDFS to stat2\n",
    "        cmd = \"ssh stat1002.eqiad.wmnet 'rm -rf %s'\" % stat2_path\n",
    "        os.system(cmd)\n",
    "        cmd = \"ssh stat1002.eqiad.wmnet 'hadoop fs -copyToLocal %s %s '\" % (hdfs_path, stat2_path)\n",
    "        os.system(cmd)\n",
    "        #transfer from stat2 to local\n",
    "        cmd = 'rm -rf %s' % local_path\n",
    "        os.system(cmd)\n",
    "        cmd = 'rsync -avz  stat1002.eqiad.wmnet:%s/* %s' % (stat2_path, local_path)\n",
    "        os.system(cmd)\n",
    "    \n",
    "    return local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirs = []\n",
    "for p in datasets:\n",
    "    dirs.append(transfer_partition(p, dry = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cleaning and Filtering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cf_helper(path, k = 5):\n",
    "    names = ['rev_comment', 'insertion', 'insert_only', 'rev_id', 'page_id', 'page_title', 'rev_timestamp', 'user_id', 'user_text']\n",
    "    df = pd.read_csv(path, sep = '\\t', quoting = 3, encoding = 'utf-8', header = None, usecols=range(len(names)))\n",
    "    if df.shape[0] ==0:\n",
    "        return pd.DataFrame(columns = names)\n",
    "    if df.shape[1] != len(names):\n",
    "        print(path)\n",
    "        print(df.shape)\n",
    "        return pd.DataFrame(columns = names)\n",
    "    df.columns = names\n",
    "    df = df.assign(key = lambda x: np.random.randint(0, high=5*k, size=x.shape[0]))\n",
    "    dfs = [e[1] for e in df.groupby('key')]\n",
    "    p = mp.Pool(k)\n",
    "    dfs = p.map(clean_and_filter, dfs)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_and_filter_parallel(path, k = 7):\n",
    "    files = []\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if '_0' in filename:\n",
    "                files.append(os.path.join(root, filename))\n",
    "    dfs = [cf_helper(p, k = k) for p in files]\n",
    "    df = pd.concat(dfs)\n",
    "    del df['key']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000008_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000017_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000055_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000056_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000066_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000068_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000103_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000113_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000137_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000141_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000143_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000145_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000150_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000158_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000161_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000175_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000179_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000182_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000200_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000201_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000203_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000212_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000221_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000223_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000228_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000232_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000233_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000239_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000240_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000241_0\n",
      "/Users/ellerywulczyn/talk_page_abuse/wikipedia/data/v4/user/talk_diff_no_admin_2015/000242_0\n"
     ]
    }
   ],
   "source": [
    "for path in dirs:\n",
    "    clean_and_filter_parallel(path).to_csv(path[:-1] +'.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download `block_events` and `blocked_users`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "      *\n",
    "FROM\n",
    "    enwiki.block_events\n",
    "\"\"\"\n",
    "\n",
    "block_events_df = query_hive_ssh(query, '../../data/block_events.tsv', priority = True, quoting=3, delete=False)\n",
    "block_events_df.columns = [c.split('.')[1] for c in block_events_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "      *\n",
    "FROM\n",
    "    enwiki.blocked_user\n",
    "\"\"\"\n",
    "\n",
    "blocked_user_df = query_hive_ssh(query, '../../data/blocked_user.tsv', priority = True, quoting=3, delete=False)\n",
    "blocked_user_df.columns = [c.split('.')[1] for c in blocked_user_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download NPA warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "      *\n",
    "FROM\n",
    "    enwiki.npa_warnings\n",
    "\"\"\"\n",
    "\n",
    "npa_warnings_df = query_hive_ssh(query, '../../data/npa_warnings.tsv', priority = True, quoting=3, delete=False)\n",
    "npa_warnings_df.columns = [c.split('.')[1] for c in npa_warnings_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Long term Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    user_text,\n",
    "    COUNT(*) AS num_days\n",
    "FROM\n",
    "    (SELECT\n",
    "        user_text,\n",
    "        day\n",
    "    FROM\n",
    "        (SELECT \n",
    "            rev_user_text AS user_text,\n",
    "            SUBSTR(rev_timestamp,0,8) AS day\n",
    "        FROM\n",
    "            enwiki.revision\n",
    "        WHERE\n",
    "            rev_user != 0\n",
    "            AND rev_timestamp <= '2015-01-01'\n",
    "        ) a\n",
    "    GROUP BY\n",
    "        user_text,\n",
    "        day ) b\n",
    "GROUP BY\n",
    "    user_text\n",
    "HAVING\n",
    "    COUNT(*) > 7 \n",
    "\"\"\"\n",
    "\n",
    "long_term_users_df = query_hive_ssh(query, '../../data/long_term_users.tsv', priority = True, quoting=3, delete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Annotate users by gender\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    user_id,\n",
    "    user_name as user_text,\n",
    "    up_value as gender\n",
    "FROM\n",
    "    enwiki.user_properties p,\n",
    "    enwiki.user u\n",
    "WHERE \n",
    "    p.up_user = u.user_id\n",
    "    AND up_property = 'gender'\n",
    "\"\"\"\n",
    "d_gender = query_analytics_store(query, {})\n",
    "d_gender.to_csv('../../data/genders.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onionize `all_blocked_user`\n",
    "\n",
    "We want to get the k posts before and after each block event for different values of [k1, k2, ..kn]. In order for us to grow k as we please without labeling headaches, we will create a file containing the k_i-1 through k_i posts for each block event that we have not yet labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns = 'article'\n",
    "rel_path = '../../data/samples'\n",
    "infile = os.path.join(rel_path, ns, 'all_blocked_user.tsv')\n",
    "out_dir = os.path.join(rel_path, ns, 'blocked_user_onion')\n",
    "df = pd.read_csv(infile, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6437\n",
      "0\n",
      "0.0004057884216308594\n",
      "1000\n",
      "95.09861302375793\n",
      "2000\n",
      "91.08967995643616\n",
      "3000\n",
      "102.37120795249939\n",
      "4000\n",
      "94.57161092758179\n",
      "5000\n",
      "88.98756098747253\n",
      "6000\n",
      "93.17013096809387\n",
      "[(5, 33047), (10, 22033), (20, 34280), (30, 28379), (40, 24505), (50, 22110), (60, 20376), (70, 18933), (80, 17751), (90, 16756), (100, 15943), (150, 71089), (200, 60239), (250, 52713), (300, 46206), (500, 145013), (1000, 228234)]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/v4/article/blocked_user_onion/100.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-553f5c8d2a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/%d.tsv'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ellerywulczyn/miniconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[1;32m   1342\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1344\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ellerywulczyn/miniconda3/lib/python3.5/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1524\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1525\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m                             compression=self.compression)\n\u001b[0m\u001b[1;32m   1527\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ellerywulczyn/miniconda3/lib/python3.5/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/v4/article/blocked_user_onion/100.tsv'"
     ]
    }
   ],
   "source": [
    "users = list(set(df['user_text']))\n",
    "print(len(users))\n",
    "\n",
    "k_prev = 0\n",
    "ks = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 500, 1000]\n",
    "dfs = {k:[] for k in ks}\n",
    "\n",
    "t1 = time.time()\n",
    "for i, user in enumerate(users):\n",
    "    if i % 1000 ==0:\n",
    "        print (i)\n",
    "        print(time.time()-t1)\n",
    "        t1 = time.time()\n",
    "    df_user = df[df['user_text'] == user].sort_values(by='rev_timestamp')\n",
    "    if df_user.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    block_events_df_user = block_events_df[block_events_df['user_text']==user]\n",
    "    seen_ids = set()\n",
    "\n",
    "\n",
    "    for i,r in block_events_df_user.iterrows():\n",
    "        ts = r['timestamp']\n",
    "        for k in ks:\n",
    "            df_user_pre = df_user[df_user['rev_timestamp'] <= ts][-k:]\n",
    "\n",
    "            if df_user_pre.shape[0] > 0:\n",
    "                df_user_pre = df_user_pre[df_user_pre['rev_id'].apply(lambda x: x not in seen_ids )]\n",
    "                if df_user_pre.shape[0] > 0:\n",
    "                    seen_ids.update(tuple(df_user_pre['rev_id']))\n",
    "                    dfs[k].append(df_user_pre)\n",
    "\n",
    "            df_user_post = df_user[df_user['rev_timestamp'] > ts][:k]\n",
    "            if df_user_post.shape[0] > 0:\n",
    "                df_user_post = df_user_post[df_user_post['rev_id'].apply(lambda x: x not in seen_ids ) ]\n",
    "                if df_user_post.shape[0] > 0:\n",
    "                    seen_ids.update(tuple(df_user_post['rev_id']))\n",
    "                    dfs[k].append(df_user_post)\n",
    "\n",
    "dfs = {k: pd.concat(v) for k,v in dfs.items()}\n",
    "\n",
    "sizes = [(k, len(v)) for k,v in dfs.items()]\n",
    "sizes.sort(key=lambda x: x[0])\n",
    "print(sizes)\n",
    "\n",
    "\n",
    "os.system('rm -rf %s' % out_dir)\n",
    "os.system('mkdir  %s' % out_dir)\n",
    "\n",
    "for k, v in dfs.items():\n",
    "    v.iloc[np.random.permutation(len(v))].to_csv(out_dir +'/%d.tsv' % k, sep = '\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
