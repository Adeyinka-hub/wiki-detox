{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harassment and Newcomer Retention\n",
    "\n",
    "In this notebook we investigate how receiving harassment correlates with newcomer activity and retention. For the purposes of this study, our measures of harassment are classifiers over individual discussion comments for personal attacks, aggression and toxicity. These classifiers were developed [in previous work](https://arxiv.org/abs/1610.08914). We will investigate the relationship between harassment and newcomer retention through running regression models that use a measures of editing activity and harassment in time span t1 as independent variables and a measure of harassment in time span t2 as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import statsmodels.formula.api as sm\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data for 2013, 2014, 2015 newcomers\n",
    "\n",
    "The data used in this analysis includes:\n",
    "1. all user and article talk page comments, labeled by harassment classifiers, except those generated by bots or templates\n",
    "2. all newly registered users, who made at least one edit\n",
    "3. edits per day per namespace for all newcomers\n",
    "4. user warnings received by 2015 newcomers in\n",
    "5. genders of all editors if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load scord diffs for 2015, drop admin and bot messages\n",
    "usecols = [3,5,7,8,9,10,11,12,13]\n",
    "\n",
    "nss = ['user', 'article']\n",
    "years = [2011, 2012, 2013, 2014, 2015]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    for ns in nss:\n",
    "\n",
    "        df = pd.read_csv(\"../../data/figshare/scored/comments_%s_%d.tsv.gz\" % (ns, year),\n",
    "                         sep = \"\\t\",\n",
    "                         compression = \"gzip\",\n",
    "                         usecols = usecols)\n",
    "        df['ns'] = ns\n",
    "        df = df.query(\"bot == 0 and admin == 0\")\n",
    "        dfs.append(df)\n",
    "\n",
    "df_annotated = pd.concat(dfs)\n",
    "df_annotated['timestamp'] = pd.to_datetime(df_annotated['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>page_title</th>\n",
       "      <th>user_text</th>\n",
       "      <th>bot</th>\n",
       "      <th>admin</th>\n",
       "      <th>key</th>\n",
       "      <th>pred_attack_score</th>\n",
       "      <th>pred_aggression_score</th>\n",
       "      <th>pred_toxicity_score</th>\n",
       "      <th>ns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-08 10:44:41</td>\n",
       "      <td>27.114.174.55</td>\n",
       "      <td>49.213.35.189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108899</td>\n",
       "      <td>0.403929</td>\n",
       "      <td>0.061511</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-12-08 14:32:18</td>\n",
       "      <td>Angelstar~enwiki</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-12-08 15:25:12</td>\n",
       "      <td>Mxrider21</td>\n",
       "      <td>NawlinWiki</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2011-12-08 20:38:11</td>\n",
       "      <td>72.152.65.231</td>\n",
       "      <td>Vyselink</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011-12-08 18:56:42</td>\n",
       "      <td>Imperious2780</td>\n",
       "      <td>Gaijin42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp        page_title      user_text  bot  admin  key  \\\n",
       "1  2011-12-08 10:44:41     27.114.174.55  49.213.35.189  0.0    0.0    0   \n",
       "6  2011-12-08 14:32:18  Angelstar~enwiki          Kelly  0.0    0.0    0   \n",
       "7  2011-12-08 15:25:12         Mxrider21     NawlinWiki  0.0    0.0    0   \n",
       "19 2011-12-08 20:38:11     72.152.65.231       Vyselink  0.0    0.0    0   \n",
       "20 2011-12-08 18:56:42     Imperious2780       Gaijin42  0.0    0.0    0   \n",
       "\n",
       "    pred_attack_score  pred_aggression_score  pred_toxicity_score    ns  \n",
       "1            0.108899               0.403929             0.061511  user  \n",
       "6            0.001226               0.004074             0.000133  user  \n",
       "7            0.003002               0.002622             0.004874  user  \n",
       "19           0.002464               0.003260             0.008621  user  \n",
       "20           0.001708               0.005992             0.001267  user  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# registration times of all editors who registered in 2015 and who made and edit\n",
    "df_user_start = pd.read_csv(\"../../data/retention/newcomer_user_start.tsv\", \"\\t\")\n",
    "df_user_start['registration_day'] = pd.to_datetime(df_user_start['registration_day'], format = '%Y%m%d')\n",
    "df_user_start['first_edit_day'] = pd.to_datetime(df_user_start['first_edit_day'], format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load edits per day in 2015 for new users in 2015\n",
    "df_edits = pd.read_csv(\"../../data/retention/newcomer_daily_revision_counts.tsv\", \"\\t\")\n",
    "df_edits['timestamp'] = pd.to_datetime(df_edits['day'].apply(lambda x: str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load user warnings recieved by 2015_newcomers\n",
    "df_uw = pd.read_csv(\"../../data/retention/newcomer_user_warnings.tsv\", \"\\t\")\n",
    "df_uw['timestamp'] = pd.to_datetime(df_uw['rev_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# genders for all editors\n",
    "df_gender = pd.read_csv(\"../../data/misc/genders.tsv\", \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create df of consolidated user level features\n",
    "df_user = df_edits.drop_duplicates(subset = 'user_text')[['user_text']]\n",
    "df_user = df_user.merge(df_gender, on = 'user_text', how = \"left\")[['user_text', 'gender']]\n",
    "df_user['gender'] = df_user['gender'].fillna('unknown')\n",
    "df_user = df_user.merge(df_user_start, on = 'user_text', how = \"inner\")[['user_text', 'gender', 'registration_day', 'first_edit_day']]\n",
    "del df_user_start\n",
    "del df_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group data by user\n",
    "To be able help with extracting user level features, we group data sources above by user and store the results in a dedicated `User` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map data frames into dictionaries keyed by user\n",
    "def gb_to_dict(gb):\n",
    "    return { i:k for i,k in gb}\n",
    "\n",
    "df_annotated_user_text_groups = gb_to_dict(df_annotated.groupby(\"user_text\"))\n",
    "df_annotated_page_title_groups =  gb_to_dict(df_annotated.query(\"ns == 'user'\").groupby(\"page_title\"))\n",
    "df_edits_groups =  gb_to_dict(df_edits.groupby(\"user_text\"))\n",
    "df_user_groups =  gb_to_dict(df_user.groupby(\"user_text\"))\n",
    "df_uw_groups =  gb_to_dict(df_uw.groupby(\"page_title\")) # page title is the recipient of the uw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect User objects \n",
    "class User():\n",
    "    def __init__(self, user_text, df_annotated_user_text_groups, df_annotated_page_title_groups, df_edits_groups, df_user_groups, df_uw_groups):\n",
    "        self.user_text = user_text\n",
    "        self.df_activity =  df_edits_groups.get(user_text, None)\n",
    "        self.df_comments_made =  df_annotated_user_text_groups.get(user_text, None)\n",
    "        self.df_comments_received = df_annotated_page_title_groups.get(user_text, None)\n",
    "        self.df_uw = df_uw_groups.get(user_text, None)\n",
    "        if self.df_comments_received is not None:\n",
    "            self.df_comments_received = self.df_comments_received.query(\"ns == 'user' and user_text != page_title\")\n",
    "        self.gender = df_user_groups[user_text]['gender'].iloc[0]\n",
    "        self.registration_day = df_user_groups[user_text]['registration_day'].iloc[0]\n",
    "        self.first_edit_day = df_user_groups[user_text]['first_edit_day'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select newcomer sample\n",
    "\n",
    "We will select all newcomers who received some form harassment as determined by one of our comment-level harassment classifiers and a sample of 50000 randomly selected newcomers. This is to speed up implementation, but we can run the regressions on all data at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.425\n",
    "\n",
    "new_user_texts = df_user.query(\"registration_day <= '2015-10-01'\")[['user_text']]\n",
    "print(\"Total New Users: \", new_user_texts.shape[0])\n",
    "\n",
    "df_bad_comments = df_annotated.query(\"pred_attack_score > %f \\\n",
    "                                      or pred_aggression_score > %f \\\n",
    "                                      or pred_toxicity_score > %f\" % (threshold, threshold, threshold))\n",
    "\n",
    "attacked_users = df_bad_comments.query(\"ns == 'user' and user_text != page_title\")\\\n",
    "                                .drop_duplicates(['page_title'])\n",
    "    \n",
    "attacked_users = attacked_users[['page_title']]\n",
    "new_attacked_users = attacked_users.merge(new_user_texts, right_on = 'user_text', left_on = 'page_title')[['user_text']]\n",
    "print(\"Total New Harrassed Users: \", new_attacked_users.shape[0])\n",
    "\n",
    "# stratified sample\n",
    "n_random = 100000\n",
    "random_new_user_texts_sample = new_user_texts.sample(n_random)\n",
    "new_user_texts_sample = pd.concat([random_new_user_texts_sample, new_attacked_users]).drop_duplicates()\n",
    "\n",
    "#new_user_texts_sample = new_user_texts\n",
    "\n",
    "user_objects = [User( user_text,\n",
    "                      df_annotated_user_text_groups,\n",
    "                      df_annotated_page_title_groups,\n",
    "                      df_edits_groups,\n",
    "                      df_user_groups, \n",
    "                      df_uw_groups) \n",
    "                for user_text in new_user_texts_sample['user_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "Our measures of user activity over a time span include:\n",
    "1. number of edits in all namespaces\n",
    "2. number of days active (a user is active on a day if they make at least on edit in any namespace)\n",
    "3. number of edit sessions (an edit session is a sequence of edits without a gap of 60 minutes or more)\n",
    "4. indicator of whether the user made at least one edit in any namespace\n",
    "\n",
    "\n",
    "Our measures of harassment received/made over a time span are:\n",
    "1. number of a comments received/made that classifier `clf` scored above `threshold`\n",
    "2. number of a comments received/made that scored above `threshold` for any of our 3 harassment classifers\n",
    "4. indicator of whether the user received/made at least one comment that scored above `threshold` for any of our 3 harassment classifiers\n",
    "\n",
    "\n",
    "We also gather:\n",
    "1. each users gender\n",
    "2. and the number of user warnings the editor received\n",
    "\n",
    "As mentioned above we, gather activity and harassment features for newcomers in timespan t1 and see how they correlate with activity features in timespan t2.\n",
    "\n",
    "In the following analysis, the two time spans we are interested in are the first and second month after user registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_month_since_registration(user,  activity, t):\n",
    "    start = user.registration_day + relativedelta(months=(t-1))\n",
    "    stop = user.registration_day + relativedelta(months= t)\n",
    "    activity = activity[activity['timestamp'] < stop]\n",
    "    activity = activity[activity['timestamp'] >= start]\n",
    "    return activity\n",
    "\n",
    "def count_edits(user, t):\n",
    "    activity = user.df_activity\n",
    "    activity = select_month_since_registration(user,  activity, t)\n",
    "    return activity['n_revisions'].sum()\n",
    "\n",
    "def count_days_active(user, t):\n",
    "    activity = user.df_activity\n",
    "    activity = select_month_since_registration(user,  activity, t)\n",
    "    return len(activity.timestamp.unique())\n",
    "\n",
    "def count_score_received_above_threshold(user, score, threshold, t):\n",
    "    if user.df_comments_received is None:\n",
    "        return 0\n",
    "    \n",
    "    comments = user.df_comments_received\n",
    "    comments = select_month_since_registration(user,  comments, t)\n",
    "    return (comments[score] > threshold).sum()\n",
    "\n",
    "def count_score_made_above_threshold(user, score, threshold, t):\n",
    "    if user.df_comments_made is None:\n",
    "        return 0\n",
    "    \n",
    "    comments = user.df_comments_made\n",
    "    comments = select_month_since_registration(user,  comments, t)\n",
    "    return (comments[score] > threshold).sum()\n",
    "\n",
    "def is_female(u):\n",
    "    return int(u.gender == 'female')\n",
    "\n",
    "def is_male(u):\n",
    "    return int(u.gender == 'male')\n",
    "\n",
    "def count_warnings_received(user, t):\n",
    "    warnings = user.df_uw\n",
    "    if warnings is None:\n",
    "        return 0\n",
    "    warnings = select_month_since_registration(user, warnings, t)\n",
    "    return len(warnings)\n",
    "\n",
    "def count_fraction_of_ns0_revisions_x(user, x, t):\n",
    "    \n",
    "    if user.df_activity is None:\n",
    "        return 0\n",
    "    \n",
    "    activity = user.df_activity.query(\"ns=='0'\")\n",
    "    activity = select_month_since_registration(user,  activity, t)\n",
    "        \n",
    "    if activity['n_revisions'].sum() < 1:\n",
    "        return 0\n",
    "    \n",
    "    return  float(activity[x].sum()) / activity['n_revisions'].sum()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame({\n",
    "        'user_text' : [u.user_text for u in user_objects],\n",
    "        'is_female' : [is_female(u) for u in user_objects],\n",
    "        'is_male' : [is_male(u) for u in user_objects],\n",
    "        't1_num_edits' : [count_edits(u, 1) for u in user_objects],\n",
    "        't2_num_edits' : [count_edits(u, 2) for u in user_objects],\n",
    "        't1_num_days_active' : [count_days_active(u, 1) for u in user_objects],\n",
    "        't2_num_days_active' : [count_days_active(u, 2) for u in user_objects],\n",
    "        't1_num_attacks_received' : [count_score_received_above_threshold(u, 'pred_attack_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_aggression_received' : [count_score_received_above_threshold(u,  'pred_aggression_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_toxicity_received' : [count_score_received_above_threshold(u,  'pred_toxicity_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_attacks_made' : [count_score_made_above_threshold(u, 'pred_attack_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_aggresssion_made': [count_score_made_above_threshold(u,  'pred_aggression_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_toxicity_made': [count_score_made_above_threshold(u,  'pred_toxicity_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_warnings_recieved' : [count_warnings_received(u, 1) for u in user_objects],\n",
    "        't1_fraction_ns0_deleted' : [count_fraction_of_ns0_revisions_x(u, 'n_deleted_revisions', 1) for u in user_objects],\n",
    "        't1_fraction_ns0_reverted' : [count_fraction_of_ns0_revisions_x(u, 'n_identity_reverted_revisions', 1) for u in user_objects],\n",
    "        't1_fraction_ns0_productive' : [count_fraction_of_ns0_revisions_x(u, 'n_productive_revisions', 1) for u in user_objects],\n",
    "\n",
    "    })\n",
    "\n",
    "df_features.shape\n",
    "\n",
    "df_features['t1_active'] = (df_features['t1_num_edits'] > 0).apply(int)\n",
    "df_features['t2_active'] = (df_features['t2_num_edits'] > 0).apply(int)\n",
    "df_features['t1_harassment_received'] = ((df_features['t1_num_attacks_received'] > 0) | (df_features['t1_num_aggression_received'] > 0) | (df_features['t1_num_toxicity_received'] > 0)).apply(int)\n",
    "df_features['t1_harassment_made'] = ((df_features['t1_num_attacks_made'] > 0) | (df_features['t1_num_aggresssion_made'] > 0) | (df_features['t1_num_toxicity_made'] > 0)).apply(int)\n",
    "df_features['has_gender'] = ((df_features[\"is_female\"] == 1) | (df_features[\"is_male\"] == 1)).apply(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_features.index = df_features.user_text\n",
    "del df_features['user_text']\n",
    "df_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the full newcomers population\n",
    "\n",
    "We are interested in running our regression models on the following subsets of the entire newcomer population:\n",
    "\n",
    "1. User who made at least one edit in t1 (active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_active = df_features.query('t1_active ==1')\n",
    "print(df_active.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Modeling\n",
    "\n",
    "In this section we explore various regression models that use a measures of editing activity and harassment in time span t1 as independent variables and a measure of harassment in time span t2 as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_reg = df_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regress(df, formula, family = 'linear'):\n",
    "    if family == 'linear':\n",
    "        result = sm.ols(formula=f, data=df).fit()\n",
    "    elif family == 'logistic':\n",
    "        result = sm.logit(formula=f, data=df).fit(disp=0)\n",
    "    else:\n",
    "        print(\"Wrong Family\")\n",
    "    return result.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: Does receiving harassment in t1 make you less likely to make an edit t2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = \"t2_active ~ t1_harassment_received\"\n",
    "regress(df_reg, f, family = 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model suggests that users who receive harassment have increased probability of being active in t2, compared to users who did not receive harassment. Lets control for how active the user was in t1 to see if the result holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f =\"t2_active ~ t1_harassment_received + t1_num_days_active\"\n",
    "regress(df_reg, f, family = 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After controlling for the number of days a user was active in t1, we see that users receiving harassment have a decreased probability of activity in t2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression: Is harassment correlated with reduction in activity from t1 to t2?\n",
    "\n",
    "Instead of running a logistic regression using an indicator for activity in t2 as our dependent variable, we will run a linear regression using the the number of days active in t2 as our dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f =\"t2_num_days_active ~ t1_harassment_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar results as above. Without controlling for activity in t1, users who receive harassment have, on average, more active days in t2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f= \"t2_num_days_active ~ t1_num_days_active + t1_harassment_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when we control for the number of days a user is active in t1, we see that users who receive harassment have fewer active days in t2. The coefficient is significantly less than 0 and larger in magnitude as on the number of active days in t1. Instead of using an indicator for whether the user received harassment, lets use the count of various types of harassment received (i.e personal attacks, aggression, toxicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f= \"t2_num_days_active ~ t1_num_days_active + t1_num_attacks_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f =\"t2_num_days_active ~ t1_num_days_active + t1_num_aggression_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + t1_num_toxicity_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the same general pattern as above, accept that toxic comments received seem to have a weaker association with lower activity in t2 than personal attacks and aggression. Also, the magnitude of the coefficients decreased since we are using a count and not an indicator as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we regress an activity measure in t2 on an activity measure in t1 and multiple measures of harassment, lets see how our different measures of harassment correlate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr \n",
    "print(pearsonr(df_reg['t1_num_attacks_received'] ,  df_reg['t1_num_aggression_received']))\n",
    "print(pearsonr(df_reg['t1_num_toxicity_received'] , df_reg['t1_num_aggression_received']))\n",
    "print(pearsonr(df_reg['t1_num_toxicity_received'] , df_reg['t1_num_attacks_received']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal attacks and aggression are very highly correlated. This is probably because both questions appeared on the same form. The toxicity measure has a lower though still high correlation with both personal attacks and aggression. Let's try a regression using toxicity and one of the two other measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + t1_num_toxicity_received + t1_num_attacks_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is harder to interpret due to the strong correlation between `t1_num_toxicity_received` and `t1_num_attacks_received`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression: How do gender, harassment and activity interact?\n",
    "\n",
    "Gender in Wikiedia is not well defined. After registering, users have the ability to report their gender in their user preferences. The vast majority of users do not report their gender. This may be because reporting their gender is not important to them, they don't want to report a gender, or they simply are unaware of the feature. There is anectodital evidence that users often report an incorrect gender. Overall, this means that we should expect users who report their gender to be different than the rest and we cannot be sure if reported genders are correct. Another caveat for the following analysis is that we do not know when the user reported their gender; they may have changed their user preference after our 2 month interval of interest.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t1_harassment_received ~ has_gender\"\n",
    "regress(df_reg, f, family = 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users who supply a gender are more likely to receive harassment! Lets see if this is different for males and females:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t1_harassment_received ~ is_female\"\n",
    "regress(df_reg.query(\"has_gender == 1\"), f, family = 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females have an increased probability of receiving harassment in t1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_active ~ has_gender\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users who supply a gender are also more likely to be active in t2! Again, lets see if this is different for males and females:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_active ~ is_female\"\n",
    "regress(df_reg.query(\"has_gender == 1\"), f, family = 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females have a descreased probability of being active in t1, although the effect is not significant. Lets see what happens when we control for activity in t1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + has_gender\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users who supply a gender appear to be more active in t2 even after controlling for activity in t1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + is_female\"\n",
    "regress(df_reg.query(\"has_gender == 1\"), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females appear to have decreased activity in t2 even after controlling for activity in t1 compared to males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + t1_harassment_received * has_gender\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like users who supply a gender and receive harassment have even more strongly reduced activity in t2 compared to users who do not supply a gender and get harassed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + t1_harassment_received * is_female\"\n",
    "regress(df_reg.query(\"has_gender == 1\"), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the effect is not significant, it seems like females who receive harassment have even more strongly reduced activity in t2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression: addressing the bad newcomer confound\n",
    "\n",
    "A serious potential confound in our analyses could be that the users who receive harassment are just bad faith newcomers or sock-puppets. They get attacked for their misbehavior and reduce their activity in t2 because they get blocked or because they never intended to stick around past their own attacks. To reduce this confound, we control for whether the user harassed anyone in t1 and for whether they received an user warning of any type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + t1_harassment_received + t1_harassment_made * t1_harassment_received + t1_num_warnings_recieved * t1_harassment_received \"\n",
    "regress(df_active, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even users who receive harassment but did not harass anyone or receive a user warning show reduced activity in t2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression: addressing the bad newcomer confound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate some newcomer experiences\n",
    "\n",
    "Our regression analyses have established that newcomer who receive harassment show a greater subsequent decline in activity than normal. Let's look at a few example of newcomers, what edits they made and how other interacted with them."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
