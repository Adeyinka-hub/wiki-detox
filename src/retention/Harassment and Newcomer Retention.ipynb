{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harassment and Newcomer Retention\n",
    "\n",
    "In this notebook we investigate how receiving harassment correlates with newcomer activity and retention. For the purposes of this study, our measures of harassment are classifiers over individual discussion comments for personal attacks, aggression and toxicity. These classifiers were developed [in previous work](https://arxiv.org/abs/1610.08914). We will investigate the relationship between harassment and newcomer retention through running regression models that use a measures of editing activity and harassment in time span t1 as independent variables and a measure of harassment in time span t2 as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import statsmodels.formula.api as sm\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data for 2015 newcomers\n",
    "\n",
    "The data used in this analysis includes:\n",
    "1. all user and article talk page comments made in 2015, labeled by harassment classifiers, except those generated by bots or templates\n",
    "2. all newly registered users, who made at least one edit in 2015 (2015 newcomers)\n",
    "3. edits per day per namespace for all 2015 newcomers\n",
    "4. user warnings received by 2015 newcomers in 2015\n",
    "5. genders of all editors if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load scord diffs for 2015, drop admin and bot messages\n",
    "usecols = [0,3,4,5,6,7,8,9,10,11,12,13]\n",
    "\n",
    "d1 = pd.read_csv(\"../../data/figshare/scored/comments_user_2015.tsv.gz\",\n",
    "                 sep = \"\\t\",\n",
    "                 compression = \"gzip\",\n",
    "                 usecols = usecols)\n",
    "d1['ns'] = 'user'\n",
    "d1 = d1.query(\"bot == 0 and admin == 0\")\n",
    "\n",
    "\n",
    "d2 = pd.read_csv(\"../../data/figshare/scored/comments_article_2015.tsv.gz\",\n",
    "                 sep = \"\\t\",\n",
    "                 compression = \"gzip\",\n",
    "                 usecols = usecols)\n",
    "d2['ns'] = 'article'\n",
    "d2 = d2.query(\"bot == 0 and admin == 0\")\n",
    "\n",
    "df_annotated = pd.concat([d1,d2])\n",
    "df_annotated['timestamp'] = pd.to_datetime(df_annotated['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# registration times of all editors who registered in 2015 and who made and edit\n",
    "df_user_start = pd.read_csv(\"../../data/retention/2015_newcomer_user_start.tsv\", \"\\t\")\n",
    "df_user_start['registration_day'] = pd.to_datetime(df_user_start['registration_day'], format = '%Y%m%d')\n",
    "df_user_start['first_edit_day'] = pd.to_datetime(df_user_start['first_edit_day'], format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load edits per day in 2015 for new users in 2015\n",
    "df_edits = pd.read_csv(\"../../data/retention/2015_newcomer_daily_edit_counts.tsv\", \"\\t\")\n",
    "df_edits['timestamp'] = pd.to_datetime(df_edits['day'].apply(lambda x: str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load user warnings recieved by 2015_newcomers\n",
    "df_uw = pd.read_csv(\"../../data/retention/2015_newcomer_user_warnings.tsv\", \"\\t\")\n",
    "df_uw['timestamp'] = pd.to_datetime(df_uw['rev_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# genders for all editors\n",
    "df_gender = pd.read_csv(\"../../data/misc/genders.tsv\", \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create df of consolidated user level features\n",
    "df_user = df_edits.drop_duplicates(subset = 'user_text')[['user_text']]\n",
    "df_user = df_user.merge(df_gender, on = 'user_text', how = \"left\")[['user_text', 'gender']]\n",
    "df_user['gender'] = df_user['gender'].fillna('unknown')\n",
    "df_user = df_user.merge(df_user_start, on = 'user_text', how = \"inner\")[['user_text', 'gender', 'registration_day', 'first_edit_day']]\n",
    "del df_user_start\n",
    "del df_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group data by user\n",
    "To be able help with extracting user level features, we group data sources above by user and store the results in a dedicated `User` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map data frames into dictionaries keyed by user\n",
    "def gb_to_dict(gb):\n",
    "    return { i:k for i,k in gb}\n",
    "\n",
    "df_annotated_user_text_groups = gb_to_dict(df_annotated.groupby(\"user_text\"))\n",
    "df_annotated_page_title_groups =  gb_to_dict(df_annotated.query(\"ns == 'user'\").groupby(\"page_title\"))\n",
    "df_edits_groups =  gb_to_dict(df_edits.groupby(\"user_text\"))\n",
    "df_user_groups =  gb_to_dict(df_user.groupby(\"user_text\"))\n",
    "df_uw_groups =  gb_to_dict(df_uw.groupby(\"page_title\")) # page title is the recipient of the uw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect User objects \n",
    "class User():\n",
    "    def __init__(self, user_text, df_annotated_user_text_groups, df_annotated_page_title_groups, df_edits_groups, df_user_groups, df_uw_groups):\n",
    "        self.user_text = user_text\n",
    "        self.df_activity =  df_edits_groups.get(user_text, None)\n",
    "        self.df_comments_made =  df_annotated_user_text_groups.get(user_text, None)\n",
    "        self.df_comments_received = df_annotated_page_title_groups.get(user_text, None)\n",
    "        self.df_uw = df_uw_groups.get(user_text, None)\n",
    "        if self.df_comments_received is not None:\n",
    "            self.df_comments_received = self.df_comments_received.query(\"ns == 'user' and user_text != page_title\")\n",
    "        self.gender = df_user_groups[user_text]['gender'].iloc[0]\n",
    "        self.registration_day = df_user_groups[user_text]['registration_day'].iloc[0]\n",
    "        self.first_edit_day = df_user_groups[user_text]['first_edit_day'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select newcomer sample\n",
    "\n",
    "We will select all newcomers who received some form harassment as determined by one of our comment-level harassment classifiers and a sample of 50000 randomly selected newcomers. This is to speed up implementation, but we can run the regressions on all data at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.425\n",
    "\n",
    "new_user_texts = df_user.query(\"registration_day <= '2015-10-01'\")[['user_text']]\n",
    "print(\"Total New Users: \", new_user_texts.shape[0])\n",
    "\n",
    "df_bad_comments = df_annotated.query(\"pred_attack_score > %f \\\n",
    "                                      or pred_aggression_score > %f \\\n",
    "                                      or pred_toxicity_score > %f\" % (threshold, threshold, threshold))\n",
    "\n",
    "attacked_users = df_bad_comments.query(\"ns == 'user' and user_text != page_title\")\\\n",
    "                                .drop_duplicates(['page_title'])\n",
    "    \n",
    "attacked_users = attacked_users[['page_title']]\n",
    "new_attacked_users = attacked_users.merge(new_user_texts, right_on = 'user_text', left_on = 'page_title')[['user_text']]\n",
    "print(\"Total New Harrassed Users: \", new_attacked_users.shape[0])\n",
    "\n",
    "# stratified sample\n",
    "n_random = 50000\n",
    "random_new_user_texts_sample = new_user_texts.sample(n_random)\n",
    "new_user_texts_sample = pd.concat([random_new_user_texts_sample, new_attacked_users]).drop_duplicates()\n",
    "\n",
    "#new_user_texts_sample = new_user_texts\n",
    "\n",
    "user_objects = [User( user_text,\n",
    "                      df_annotated_user_text_groups,\n",
    "                      df_annotated_page_title_groups,\n",
    "                      df_edits_groups,\n",
    "                      df_user_groups, \n",
    "                      df_uw_groups) \n",
    "                for user_text in new_user_texts_sample['user_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "Our measures of user activity over a time span include:\n",
    "1. number of edits in all namespaces\n",
    "2. number of days active (a user is active on a day if they make at least on edit in any namespace)\n",
    "3. number of edit sessions (an edit session is a sequence of edits without a gap of 60 minutes or more)\n",
    "4. indicator of whether the user made at least one edit in any namespace\n",
    "\n",
    "\n",
    "Our measures of harassment received/made over a time span are:\n",
    "1. number of a comments received/made that classifier `clf` scored above `threshold`\n",
    "2. number of a comments received/made that scored above `threshold` for any of our 3 harassment classifers\n",
    "4. indicator of whether the user received/made at least one comment that scored above `threshold` for any of our 3 harassment classifiers\n",
    "\n",
    "\n",
    "We also gather:\n",
    "1. each users gender\n",
    "2. and the number of user warnings the editor received\n",
    "\n",
    "As mentioned above we, gather activity and harassment features for newcomers in timespan t1 and see how they correlate with activity features in timespan t2.\n",
    "\n",
    "In the following analysis, the two time spans we are interested in are the first and second month after user registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_month_since_registration(user,  activity, t):\n",
    "    start = user.registration_day + relativedelta(months=(t-1))\n",
    "    stop = user.registration_day + relativedelta(months= t)\n",
    "    activity = activity[activity['timestamp'] < stop]\n",
    "    activity = activity[activity['timestamp'] >= start]\n",
    "    return activity\n",
    "\n",
    "def count_edits(user, t):\n",
    "    activity = user.df_activity\n",
    "    activity = select_month_since_registration(user,  activity, t)\n",
    "    return activity['n'].sum()\n",
    "\n",
    "def count_days_active(user, t):\n",
    "    activity = user.df_activity\n",
    "    activity = select_month_since_registration(user,  activity, t)\n",
    "    return len(activity.timestamp.unique())\n",
    "\n",
    "def count_score_received_above_threshold(user, score, threshold, t):\n",
    "    if user.df_comments_received is None:\n",
    "        return 0\n",
    "    \n",
    "    comments = user.df_comments_received\n",
    "    comments = select_month_since_registration(user,  comments, t)\n",
    "    return (comments[score] > threshold).sum()\n",
    "\n",
    "def count_score_made_above_threshold(user, score, threshold, t):\n",
    "    if user.df_comments_made is None:\n",
    "        return 0\n",
    "    \n",
    "    comments = user.df_comments_made\n",
    "    comments = select_month_since_registration(user,  comments, t)\n",
    "    return (comments[score] > threshold).sum()\n",
    "\n",
    "def is_female(u):\n",
    "    return u.gender == 'female'\n",
    "\n",
    "def is_male(u):\n",
    "    return u.gender == 'male'\n",
    "\n",
    "def count_warnings_received(user, t):\n",
    "    warnings = user.df_uw\n",
    "    if warnings is None:\n",
    "        return 0\n",
    "    warnings = select_month_since_registration(user,  warnings, t)\n",
    "    return len(warnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame({\n",
    "        'user_text' : [u.user_text for u in user_objects],\n",
    "        'is_female' : [is_female(u) for u in user_objects],\n",
    "        'is_male' : [is_male(u) for u in user_objects],\n",
    "        't1_num_edits' : [count_edits(u, 1) for u in user_objects],\n",
    "        't2_num_edits' : [count_edits(u, 2) for u in user_objects],\n",
    "        't1_num_days_active' : [count_days_active(u, 1) for u in user_objects],\n",
    "        't2_num_days_active' : [count_days_active(u, 2) for u in user_objects],\n",
    "        't1_num_attacks_received' : [count_score_received_above_threshold(u, 'pred_attack_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_aggression_received' : [count_score_received_above_threshold(u,  'pred_aggression_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_toxicity_received' : [count_score_received_above_threshold(u,  'pred_toxicity_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_attacks_made' : [count_score_made_above_threshold(u, 'pred_attack_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_aggresssion_made': [count_score_made_above_threshold(u,  'pred_aggression_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_toxicity_made': [count_score_made_above_threshold(u,  'pred_toxicity_score',  threshold, 1) for u in user_objects],\n",
    "        't1_num_warnings_recieved' : [count_warnings_received(u, 1) for u in user_objects],\n",
    "    })\n",
    "\n",
    "df_features.shape\n",
    "\n",
    "df_features['t1_active'] = df_features['t1_num_edits'] > 0\n",
    "df_features['t2_active'] = df_features['t2_num_edits'] > 0\n",
    "df_features['t1_harassment_received'] = (df_features['t1_num_attacks_received'] > 0) | (df_features['t1_num_aggression_received'] > 0) | (df_features['t1_num_toxicity_received'] > 0)\n",
    "df_features['t1_harassment_made'] = (df_features['t1_num_attacks_made'] > 0) | (df_features['t1_num_aggresssion_made'] > 0) | (df_features['t1_num_toxicity_made'] > 0)\n",
    "\n",
    "df_features.index = df_features.user_text\n",
    "del df_features['user_text']\n",
    "df_features = df_features.astype(int)\n",
    "df_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the full newcomers population\n",
    "\n",
    "We are interested in running our regression models on the following subsets of the entire newcomer population:\n",
    "\n",
    "1. User who made at least one edit in t1 (active)\n",
    "2. Active users who did not make a harassing comment directed at another user in t1 (active, friendly)\n",
    "3. Active, friendly users who did not receive a user warning in t1 (active, friendly, golden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_active = df_features.query('t1_active ==1')\n",
    "print(df_active.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_active_friendly = df_features.query('t1_active ==1 and t1_harassment_made == 0')\n",
    "print(df_active_friendly.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_active_friendly_golden = df_features.query('t1_active ==1 and t1_harassment_made == 0 and t1_num_warnings_recieved == 0')\n",
    "print(df_active_friendly_golden.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Modeling\n",
    "\n",
    "In this section we explore various regression models that use a measures of editing activity and harassment in time span t1 as independent variables and a measure of harassment in time span t2 as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_reg = df_active_friendly_golden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regress(df, formula, family = 'linear'):\n",
    "    if family == 'linear':\n",
    "        result = sm.ols(formula=f, data=df).fit()\n",
    "    elif family == 'logistic':\n",
    "        result = sm.logit(formula=f, data=df).fit(disp=0)\n",
    "    else:\n",
    "        print(\"Wrong Family\")\n",
    "    return result.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: Does receiving harassment in t1 make you less likely to make an edit t2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = \"t2_active ~ t1_harassment_received\"\n",
    "regress(df_reg, f, family = 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model suggests that users who receive harassment have increased probability of being active in t2, compared to users who did not receive harassment. Lets control for how active the user was in t1 to see if the result holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f =\"t2_active ~ t1_harassment_received + t1_num_days_active\"\n",
    "regress(df_reg, f, family = 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After controlling for the number of days a user was active in t1, we see that users receiving harassment have a decreased probability of activity in t2, although the result is not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression: Is harassment correlated with reduction in activity from t1 to t2?\n",
    "\n",
    "Instead of running a logistic regression using an indicator for activity in t2 as our dependent variable, we will run a linear regression using the the number of days active in t2 as our dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f =\"t2_num_days_active ~ t1_harassment_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar results as above. Without controlling for activity in t1, users who receive harassment have, on average, more active days in t2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f= \"t2_num_days_active ~ t1_num_days_active + t1_harassment_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when we control for the number of days a user is active in t1, we see that users who receive harassment have fewer active days in t2. The coefficient is significantly less than 0 and as large in magnitude as on the number of active days in t1. Instead of using an indicator for whether the user received harassment, lets use the count of various types of harassment received (i.e personal attacks, aggression, toxicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f= \"t2_num_days_active ~ t1_num_days_active + t1_num_attacks_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f =\"t2_num_days_active ~ t1_num_days_active + t1_num_aggression_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + t1_num_toxicity_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the same general pattern as above, accept that toxic comments received seem to have a weaker association with lower activity in t2 than personal attacks and aggression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we regress an activity measure in t2 on an activity measure in t1 and multiple measures of harassment, lets see how our different measures of harassment correlate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr \n",
    "print(pearsonr(df_reg['t1_num_attacks_received'] ,  df_reg['t1_num_aggression_received']))\n",
    "print(pearsonr(df_reg['t1_num_toxicity_received'] , df_reg['t1_num_aggression_received']))\n",
    "print(pearsonr(df_reg['t1_num_toxicity_received'] , df_reg['t1_num_attacks_received']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal attacks and aggression are highly correlated. This is probably because both questions appeared on the same form. The toxicity measure has a moderate correlation with both personal attacks and aggression. Let's try a regression using toxicity and one of the two other measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + t1_num_toxicity_received + t1_num_attacks_received\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression: How do gender, harassment and activity interact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t1_harassment_received ~ is_female\"\n",
    "regress(df_reg, f, family = 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females have an increased probability of receiving harassment in t1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_active ~ is_female\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females are more likely to be active in t2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + is_female\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females appear to be more active in t2 than males and users who did not register a gender after controlling for activity in t1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + t1_harassment_received * is_female\"\n",
    "regress(df_reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the effect is not significant, it seems like females who receive harassment have even more strongly reduced activity in t2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression: adding user warning and harassment made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=\"t2_num_days_active ~ t1_num_days_active + t1_harassment_received + t1_harassment_made + t1_user_warnings_received\"\n",
    "regress(df_active, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate some newcomer experiences\n",
    "\n",
    "Our regression analyses have established that newcomer who receive harassment show a greater subsequent decline in activity than normal. Let's look at a few example of newcomers, what edits they made and how other interacted with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
