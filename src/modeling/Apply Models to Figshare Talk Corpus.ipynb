{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 6.13 ms\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21min 31s\n"
     ]
    }
   ],
   "source": [
    "tasks = ['attack', 'toxicity', 'aggression']\n",
    "model_dict = {}\n",
    "for task in tasks:\n",
    "    os.system(\"python get_prod_models.py --task %s\" % task) \n",
    "    model_dict[task] = joblib.load(\"/tmp/%s_linear_char_oh_pipeline.pkl\" % task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.08 ms\n"
     ]
    }
   ],
   "source": [
    "def apply_models(df):\n",
    "    comments = df['comment']\n",
    "    for task, model in model_dict.items():\n",
    "        scores = model.predict_proba(comments)[:,1]\n",
    "        df['pred_%s_score' % task] = scores\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.9 ms\n"
     ]
    }
   ],
   "source": [
    "def pred_helper(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    \n",
    "    return df.assign(timestamp = lambda x: pd.to_datetime(x.timestamp),\n",
    "                     comment = lambda x: x['comment'].astype(str))\\\n",
    "             .pipe(apply_models)\n",
    "\n",
    "    \n",
    "def prep_in_parallel(path, k = 8):\n",
    "    df = pd.read_csv(path, sep = '\\t', encoding = 'utf-8')\n",
    "    m = df.shape[0] \n",
    "    if m < 15000:\n",
    "        n_groups = 1\n",
    "    else:\n",
    "        n_groups = int(m / 10000.0)\n",
    "    df['key'] = np.random.randint(0, high=n_groups, size=m)\n",
    "    dfs = [e[1] for e in df.groupby('key')]\n",
    "    #dfs = [pred_helper(d) for d in dfs]\n",
    "    p = mp.Pool(k)\n",
    "    dfs = p.map(pred_helper, dfs)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments_user_2001\n",
      "chunk_0.tsv\n",
      "comments_user_2002\n",
      "chunk_0.tsv\n"
     ]
    }
   ],
   "source": [
    "base = '../../data/figshare/'\n",
    "nss = ['user', 'article']\n",
    "years = range(2001, 2016)\n",
    "\n",
    "for ns in nss:\n",
    "    for year in years:\n",
    "        \n",
    "        \n",
    "        dirname = \"comments_%s_%d\" % (ns, year)\n",
    "        print(dirname)\n",
    "        \n",
    "        indir = os.path.join(base, dirname + \".tar.gz\")\n",
    "        outf = os.path.join(base, \"scored\", dirname + \".tsv.gz\")\n",
    "        \n",
    "        os.system(\"cp %s .\" % indir)\n",
    "        os.system(\"tar -zxvf %s.tar.gz\" % dirname)\n",
    "        \n",
    "        dfs = []\n",
    "        \n",
    "        for inf in os.listdir(dirname):\n",
    "            print(inf)\n",
    "            if inf.endswith(\".tsv\"): \n",
    "                df = prep_in_parallel(os.path.join(dirname, inf), k = 8)\n",
    "                dfs.append(df)\n",
    "        os.system(\"rm -rf %s\" % dirname)\n",
    "        os.system(\"rm -rf %s.tar.gz\" % dirname)\n",
    "        pd.concat(dfs).to_csv(outf, sep = '\\t', index = False, compression = \"gzip\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
